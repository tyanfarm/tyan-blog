---
sidebar_position: 7
title: 3. Coding Attention Mechanisms (Part 05)
---

## 3.6. Cải tiến từ single-head attention sang multi-head attention

- Ở phần này ta sẽ mở rộng `multi-head attention` từ `causal attention`. 

- Triển khai đầu tiên sẽ xây dựng module _multi-head attention_ bằng cách _xếp chồng_ nhiều module `CausalAttention` để dễ hình dung.

- Sau đó triển khai tiếp theo sẽ xây dựng cùng 1 module _multi-head attention_ đó theo một cách phức tạp hơn để mang lại hiệu suất tính toán cao hơn.

### _Xếp chồng nhiều lớp single-head attention_

